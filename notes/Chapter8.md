# 第 8 章 多项式回归与模型泛化

- 线性回归的前提假设是存在线性关系
  - 但是数据之间的关系不一定是线性的

- 比如x^2的二次关系，虽然不是线性回归，但是相当于多加入特征，这个特征是原来特征的多项式项

## 过拟合和欠拟合(Overfitting, Underfitting)

- 不能随意使用多项式回归，容易出现问题

- 多项式回归使用R^2，或者使用MSE都是可以的

- 随意增加次数进行拟合，能尽可能的是所有的点存在于拟合曲线上
  - 但是该拟合曲线并不是想要的结果
  - 过拟合
    - 算法所训练的模型过多地表达了数据间的噪音关系

- 使用非常少的次数进行拟合，太过于简单
  - 欠拟合
    - 算法所训练的模型不能完整表述数据关系

## 模型的泛化能力

- 如果对一个模型过拟合，那么拟合曲线的形状可能非常奇怪
  - 出现新的数据点的时候，预测的值也可能非常奇怪，于原来的数据偏离较大
  - 此时预测能力太差，也就是**模型的泛化能力弱**
  - 面对新的数据预测能力太差

- 真正需要的是模型的泛化能力强才行

- 所以分离训练数据和测试数据的意义也就在此
  - 如果面对新的数据也能很好的预测，才能说明模型的泛化能力强

- 模型准确率vs模型复杂程度曲线
  - 对于训练数据集来说，模型复杂度越高，准确率越高
  - 对于测试数据集来说，存在一个极大值，模型复杂度比极大值还大的时候准确率降低
  - 每一个模型的复杂程度定义不一样

- 学习曲线
  - 随着训练样本的逐渐增多，算法训练出的模型的表现能力

- 使用train-test-split判断模型的泛化能力也有一个问题
  - 针对特定测试数据集产生过拟合问题
  - 因为测试数据集也是已知的，所以有可能是在对测试数据集调参

- 所以需要将数据分成三部分
  - 训练数据集训练模型，验证数据集达到最优(调整超参数使用的数据集)，测试数据集作为衡量最终模型性能的数据集
  - 训练，验证都参与模型的创建，但是测试数据是完全不可知的，不参与模型的创建

- 但是还是有问题
  - 因为是随机分割的数据集，所以如果验证数据集有极端数据可能会导致模型不准确
  - 通过交叉验证Cross Validation进行解决

## 交叉验证

- 比较正规，一般使用该方法进行调参

- 先将数据集分成训练数据集和测试数据集
- 然后将训练数据集分成k份A,B,C。然后将其中k-1个进行训练，第k个进行验证
  - 最终得到的k个模型的均值作为结果调参

- k-folds交叉验证
  - 把训练数据集分成k份，成为k-folds cross validation
- 缺点，每次训练k个模型，相当于整体性能满了k倍
  
- 极端情况下k-folds法可以变成留一法LOO-CV(Leave-One-Out Cross Validation)
  - 如果训练数据集有m个样本，就分成m份
  - 每次训练m-1个样本，用1个样本进行验证
  - 完全不受随机的影响，最接近模型真正的性能指标
  - 缺点：计算量巨大
