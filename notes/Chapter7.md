# 第 7 章 PCA与梯度上升法

- 主成分分析(Principal Component Analysis)
  - 非监督的机器学习算法
  - 主要用于数据的降维
  - 通过降维，可以发现更便于人类理解的特征
  - 可视化，去噪

## 简单理解PCA

- 如果有两个特征x和y，并且有一些点
- 降维就是使这些点压缩到一维，或者压缩到x轴，或者压缩到y轴
- 此时较好的压缩方式就是压缩完后所有点之间的间距更大，也就是区分度更大
  - 最好的方法就是找到一条直线(轴)，使得样本间间距最大

- 定义样本间间距：使用方差(Variance)
  - 描述样本疏密
  - 也就是找到一个轴，使所有样本压缩之后方差最大

- 第一步：将样本的均值归为0(demean)
  - 所有样本减去均值
  - 这样就是计算平方和最大了！

- 求一个轴的方向w=(w1, w2)，使得所有样本映射到w以后，有方差最大
  - 映射之后的模的大小就是点乘的定义
  - w是方向向量，也就是模为1

- 求一个方向向量w，使得每一个向量X和方向向量w点乘之后的方差最大

- 求最大值，使用梯度上升法解决即可

- 拓展
  - 批量梯度上升，随机梯度上升，小批量梯度上升

## 求主成分

- 求出的是主成分的轴，这个轴使现有数据映射后方差最大
  - 第一主成分之后第二主成分，第三，第四

- 如何求第一主成分之后的主成分？
  - 数据进行改变，将数据在第一个主成分上的分量去掉
  
- 映射后，向量就是点乘之后(模)乘上主成分方向向量即可

- 去除第一主成分上的分量
  - 用原有向量-(第一主成分)映射后的向量
  - 得到的是垂直于第一主成分的分量

- 在新的数据上求第一主成分即可